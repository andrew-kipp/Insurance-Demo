{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19851ecb-8c80-4d06-83ac-66cfb1410e61",
   "metadata": {},
   "source": [
    "## Import Packages, Training Data Subset, and Intermediate Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "920a212a-376f-4277-ab5f-29fdfad430fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('max_columns', None)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, PowerTransformer, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer \n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1b76e34-07fc-47fa-9731-e4ce3b7efbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/Users/akipp/Documents/GitHub/Data/Insurance-Demo-Data/'\n",
    "train_data_name = 'exercise_40_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "864f0be8-4ce8-4242-a51d-17266805d7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(data_path + train_data_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5ec7ed-e083-44ab-a37b-9eeb6c2e0559",
   "metadata": {},
   "source": [
    "## Train/Test Split and Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33a2e0b7-fe10-4af8-93e8-398542284d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    # x7 is a percentage amount which needs to be converted to a standard float value; contains some values in \n",
    "    # scientific notation which needs to be accounted for\n",
    "    def percent_to_float(x):\n",
    "        x_split = x.strip('%').split('e')\n",
    "        if len(x_split) == 2:\n",
    "            return(float(x_split[0]) * 10**float(x_split[1]))\n",
    "        else:\n",
    "            return(float(x_split[0]))\n",
    "\n",
    "    df['x7'] = df.x7.apply(percent_to_float)\n",
    "\n",
    "\n",
    "    # x19 is a dollar amount which needs to be \n",
    "    df['x19'] = df.x19.apply(lambda x: float(x.strip('$')))\n",
    "\n",
    "    # Consolidate day of week names\n",
    "    df['x3'] = df['x3'].map({'Monday': 'Monday', 'Tuesday': 'Tuesday', 'Wednesday': 'Wednesday', 'Thursday': 'Thursday', \n",
    "                             'Friday': 'Friday', 'Saturday': 'Saturday', 'Sunday': 'Sunday', \n",
    "                             'Mon': 'Monday', 'Tue': 'Tuesday', 'Wed': 'Wednesday', 'Thur': 'Thursday', \n",
    "                             'Fri': 'Friday', 'Sat': 'Saturday', 'Sun': 'Sunday'})\n",
    "    # Replace missing values of what is probably a gender or sex column with 'other'\n",
    "    df['x24'] = df.x24.fillna('other')\n",
    "    # Replace missing values of what is probably a car make or brand column with 'other'\n",
    "    df['x77'] = df.x77.fillna('other')\n",
    "    # Replace missing values in x33, x99, and x79 with 'missing' because we don't know what is missing here;\n",
    "    # Map the values in x79 to strings so it can having missing as a category and will work with OHE\n",
    "    df['x99'] = df.x99.fillna('missing')\n",
    "    df['x79'] = df['x79'].map({1.0: '1', 0.0: '0'}).fillna('missing')\n",
    "    df['x33'] = df.x33.fillna('missing')\n",
    "    # Drop columns x39 because it is not useful - only has a single value and no missing values.\n",
    "    df.drop(columns = ['x39'], inplace = True)\n",
    "    \n",
    "    # Output initially cleaned data\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "443c3984-041b-4e9e-81fe-d5778e9f09f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No issues with doing the data cleaning before train/test split because all transformations are element-wise only and there is no data leakage\n",
    "train_data = data_cleaning(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "635cf309-36be-47ab-8fcc-723927336064",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data['y']\n",
    "X = train_data.drop(columns = ['y'])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, stratify = y, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29592307-e3f8-4226-a282-81326c2ae000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36000, 99)\n",
      "(4000, 99)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffcc3ef-98b6-40ac-9bda-6387c883b002",
   "metadata": {},
   "source": [
    "## Logistic Regression Modeling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49b9d18c-027c-4d08-b869-aff4c8055f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_model_gscv(X_train, y_train, smote = True):\n",
    "    # One-Hot Enconde categorical features\n",
    "    cat_feats = X_train.columns[X_train.dtypes == 'object']\n",
    "    \n",
    "    # An imblearn pipeline is needed when using SMOTE in the pipeline because the function doesn't \n",
    "    # have a fit_transform method and can't be used with a sklearn pipeline. Also, the imblearn \n",
    "    # pipeline will ensure that SMOTE is only applied to training data, even in cross-validation.\n",
    "    if smote == True: \n",
    "        pipeline = imbpipeline(steps = [('ohe', ColumnTransformer(transformers = [('ohe', OneHotEncoder(handle_unknown = 'ignore', sparse = False), cat_feats)], remainder = 'passthrough')),\n",
    "                                        # Inputing missing continuous feature data with chained equations\n",
    "                                        ('mice', IterativeImputer(max_iter = 20, tol = 0.01, n_nearest_features = 50, random_state = 42, verbose = 1)), \n",
    "                                        # Creating synthetic data from the minority class\n",
    "                                        ('smote', SMOTE(k_neighbors = 10, random_state = 42)), \n",
    "                                        # Attempting to normalize the features with the yeo-johnson transformation (box-cox also an option, but requires all data to be positive)\n",
    "                                        ('gaussian', PowerTransformer()),\n",
    "                                        # Robust scaling of the data, rather than Standard scaling, because it is less impacted by outliers\n",
    "                                        ('scaler', RobustScaler()),\n",
    "                                        ('classifier', LogisticRegression(random_state = 42))\n",
    "                                       ])\n",
    "    # When not using SMOTE, a sklearn pipeline works fine\n",
    "    else:\n",
    "        pipeline = Pipeline(steps = [('ohe', ColumnTransformer(transformers = [('ohe', OneHotEncoder(handle_unknown = 'ignore', sparse = False), cat_feats)], remainder = 'passthrough')),\n",
    "                                     # Inputing missing continuous feature data with chained equations\n",
    "                                     ('mice', IterativeImputer(max_iter = 20, tol = 0.01, n_nearest_features = 50, random_state = 42, verbose = 1)),\n",
    "                                     # Attempting to normalize the features with the yeo-johnson transformation (box-cox also an option, but requires all data to be positive)\n",
    "                                     ('gaussian', PowerTransformer()),\n",
    "                                     # Robust scaling of the data, rather than Standard scaling, because it is less impacted by outliers\n",
    "                                     ('scaler', RobustScaler()),\n",
    "                                     ('classifier', LogisticRegression(random_state = 42))\n",
    "                                    ])\n",
    "    # Specify how the folds should be created in GridSearchCV\n",
    "    stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=42)\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    # defaults: 'penalty': 'l2', 'solver': 'lbfgs', 'max_iter': 100 (doesn't converge at 100), 'C': 1.0\n",
    "    param_grid = {'classifier__C': [0.01, 0.1, 1, 10, 100], 'classifier__max_iter': [1000]} \n",
    "    grid_search = GridSearchCV(estimator = pipeline,\n",
    "                               param_grid = param_grid,\n",
    "                               scoring = 'roc_auc',\n",
    "                               cv = stratified_kfold,\n",
    "                               n_jobs = 8,\n",
    "                               verbose = 3)\n",
    "    \n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786dca5c-032e-4517-b176-228238e391bd",
   "metadata": {},
   "source": [
    "### Logistic Regression without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449e24d7-891b-440e-88b9-b82e7048a338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[IterativeImputer] Completing matrix with shape (36000, 185)\n",
      "[IterativeImputer] Change: 4762.814312581376, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 902.9395589654421, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    }
   ],
   "source": [
    "lr_model = lr_model_gscv(X_train, y_train, smote = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa7da864-a3e1-4cd9-ba4b-857eb58db595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters determine during grid search: {'classifier__C': 0.1, 'classifier__max_iter': 1000}\n",
      "Best AUC score on cross-validation data: 0.7659928781183799\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters determine during grid search:', lr_model.best_params_)\n",
    "print('Best AUC score on cross-validation data:', lr_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af854a81-54c6-4278-8c5e-721cb4f6a27f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.387124</td>\n",
       "      <td>12.910848</td>\n",
       "      <td>0.645548</td>\n",
       "      <td>0.058682</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__max_iter'...</td>\n",
       "      <td>0.760046</td>\n",
       "      <td>0.758299</td>\n",
       "      <td>0.769281</td>\n",
       "      <td>0.769006</td>\n",
       "      <td>0.770698</td>\n",
       "      <td>0.765466</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108.068055</td>\n",
       "      <td>13.227967</td>\n",
       "      <td>0.724269</td>\n",
       "      <td>0.069899</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.760664</td>\n",
       "      <td>0.759040</td>\n",
       "      <td>0.768502</td>\n",
       "      <td>0.769648</td>\n",
       "      <td>0.772109</td>\n",
       "      <td>0.765993</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.140387</td>\n",
       "      <td>13.518889</td>\n",
       "      <td>0.734409</td>\n",
       "      <td>0.060566</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.760565</td>\n",
       "      <td>0.759048</td>\n",
       "      <td>0.768056</td>\n",
       "      <td>0.769493</td>\n",
       "      <td>0.772339</td>\n",
       "      <td>0.765900</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.636041</td>\n",
       "      <td>11.953392</td>\n",
       "      <td>0.632222</td>\n",
       "      <td>0.052137</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.760552</td>\n",
       "      <td>0.759010</td>\n",
       "      <td>0.768011</td>\n",
       "      <td>0.769428</td>\n",
       "      <td>0.772377</td>\n",
       "      <td>0.765876</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>80.777431</td>\n",
       "      <td>21.026607</td>\n",
       "      <td>0.298392</td>\n",
       "      <td>0.073922</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 100, 'classifier__max_iter':...</td>\n",
       "      <td>0.760553</td>\n",
       "      <td>0.759006</td>\n",
       "      <td>0.768003</td>\n",
       "      <td>0.769421</td>\n",
       "      <td>0.772386</td>\n",
       "      <td>0.765874</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     108.387124     12.910848         0.645548        0.058682   \n",
       "1     108.068055     13.227967         0.724269        0.069899   \n",
       "2     110.140387     13.518889         0.734409        0.060566   \n",
       "3     104.636041     11.953392         0.632222        0.052137   \n",
       "4      80.777431     21.026607         0.298392        0.073922   \n",
       "\n",
       "  param_classifier__C param_classifier__max_iter  \\\n",
       "0                0.01                       1000   \n",
       "1                 0.1                       1000   \n",
       "2                   1                       1000   \n",
       "3                  10                       1000   \n",
       "4                 100                       1000   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__C': 0.01, 'classifier__max_iter'...           0.760046   \n",
       "1  {'classifier__C': 0.1, 'classifier__max_iter':...           0.760664   \n",
       "2  {'classifier__C': 1, 'classifier__max_iter': 1...           0.760565   \n",
       "3  {'classifier__C': 10, 'classifier__max_iter': ...           0.760552   \n",
       "4  {'classifier__C': 100, 'classifier__max_iter':...           0.760553   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.758299           0.769281           0.769006           0.770698   \n",
       "1           0.759040           0.768502           0.769648           0.772109   \n",
       "2           0.759048           0.768056           0.769493           0.772339   \n",
       "3           0.759010           0.768011           0.769428           0.772377   \n",
       "4           0.759006           0.768003           0.769421           0.772386   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.765466        0.005200                5  \n",
       "1         0.765993        0.005173                1  \n",
       "2         0.765900        0.005185                2  \n",
       "3         0.765876        0.005195                3  \n",
       "4         0.765874        0.005196                4  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lr_model.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0996603-7999-4efb-bcc1-b9c78daebc4c",
   "metadata": {},
   "source": [
    "### Logistic Regression with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e420dd2b-2cd8-4bf5-98ee-b756d25b88db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[IterativeImputer] Completing matrix with shape (36000, 185)\n",
      "[IterativeImputer] Change: 4762.814312581376, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 902.9395589654421, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akipp\\anaconda3\\envs\\py38env\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "lr_model_smote = lr_model_gscv(X_train, y_train, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f1e9078-a295-40a0-8d40-acf72d4d2575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters determine during grid search: {'classifier__C': 100, 'classifier__max_iter': 1000}\n",
      "Best AUC score on cross-validation data: 0.7656243496126398\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters determine during grid search:', lr_model_smote.best_params_)\n",
    "print('Best AUC score on cross-validation data:', lr_model_smote.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4653627-a4e7-4505-bc71-67d658c702f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__C</th>\n",
       "      <th>param_classifier__max_iter</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118.235202</td>\n",
       "      <td>11.422702</td>\n",
       "      <td>0.724222</td>\n",
       "      <td>0.052898</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 0.01, 'classifier__max_iter'...</td>\n",
       "      <td>0.758626</td>\n",
       "      <td>0.757595</td>\n",
       "      <td>0.766974</td>\n",
       "      <td>0.768843</td>\n",
       "      <td>0.771542</td>\n",
       "      <td>0.764716</td>\n",
       "      <td>0.005595</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121.653897</td>\n",
       "      <td>10.382984</td>\n",
       "      <td>0.753368</td>\n",
       "      <td>0.074432</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 0.1, 'classifier__max_iter':...</td>\n",
       "      <td>0.760119</td>\n",
       "      <td>0.758592</td>\n",
       "      <td>0.767243</td>\n",
       "      <td>0.769535</td>\n",
       "      <td>0.772054</td>\n",
       "      <td>0.765509</td>\n",
       "      <td>0.005272</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>133.669401</td>\n",
       "      <td>11.520107</td>\n",
       "      <td>0.713796</td>\n",
       "      <td>0.165032</td>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 1, 'classifier__max_iter': 1...</td>\n",
       "      <td>0.760452</td>\n",
       "      <td>0.758706</td>\n",
       "      <td>0.767045</td>\n",
       "      <td>0.769565</td>\n",
       "      <td>0.772027</td>\n",
       "      <td>0.765559</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>154.719287</td>\n",
       "      <td>9.283014</td>\n",
       "      <td>0.594104</td>\n",
       "      <td>0.097337</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 10, 'classifier__max_iter': ...</td>\n",
       "      <td>0.760588</td>\n",
       "      <td>0.758636</td>\n",
       "      <td>0.767198</td>\n",
       "      <td>0.769476</td>\n",
       "      <td>0.772137</td>\n",
       "      <td>0.765607</td>\n",
       "      <td>0.005175</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127.388070</td>\n",
       "      <td>33.106193</td>\n",
       "      <td>0.302648</td>\n",
       "      <td>0.067820</td>\n",
       "      <td>100</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__C': 100, 'classifier__max_iter':...</td>\n",
       "      <td>0.760556</td>\n",
       "      <td>0.758790</td>\n",
       "      <td>0.767237</td>\n",
       "      <td>0.769321</td>\n",
       "      <td>0.772217</td>\n",
       "      <td>0.765624</td>\n",
       "      <td>0.005140</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     118.235202     11.422702         0.724222        0.052898   \n",
       "1     121.653897     10.382984         0.753368        0.074432   \n",
       "2     133.669401     11.520107         0.713796        0.165032   \n",
       "3     154.719287      9.283014         0.594104        0.097337   \n",
       "4     127.388070     33.106193         0.302648        0.067820   \n",
       "\n",
       "  param_classifier__C param_classifier__max_iter  \\\n",
       "0                0.01                       1000   \n",
       "1                 0.1                       1000   \n",
       "2                   1                       1000   \n",
       "3                  10                       1000   \n",
       "4                 100                       1000   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'classifier__C': 0.01, 'classifier__max_iter'...           0.758626   \n",
       "1  {'classifier__C': 0.1, 'classifier__max_iter':...           0.760119   \n",
       "2  {'classifier__C': 1, 'classifier__max_iter': 1...           0.760452   \n",
       "3  {'classifier__C': 10, 'classifier__max_iter': ...           0.760588   \n",
       "4  {'classifier__C': 100, 'classifier__max_iter':...           0.760556   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.757595           0.766974           0.768843           0.771542   \n",
       "1           0.758592           0.767243           0.769535           0.772054   \n",
       "2           0.758706           0.767045           0.769565           0.772027   \n",
       "3           0.758636           0.767198           0.769476           0.772137   \n",
       "4           0.758790           0.767237           0.769321           0.772217   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.764716        0.005595                5  \n",
       "1         0.765509        0.005272                4  \n",
       "2         0.765559        0.005160                3  \n",
       "3         0.765607        0.005175                2  \n",
       "4         0.765624        0.005140                1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lr_model_smote.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d1171f-c3c3-4400-9379-2bb1b80446e1",
   "metadata": {},
   "source": [
    "From the above results, it appears that while the classes are imbalanced, using SMOTE to aftifically balance the classes does not provide any particular benefit so it can be dropped from use in Logistic Regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263b3ec0-5110-4501-a939-332fe6ca9d5d",
   "metadata": {},
   "source": [
    "### Logistic Regression Intermediate Test Data Score - Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34a68615-dbb1-447a-81e8-17d79f4347de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (4000, 185)\n",
      "AUC on test data: 0.7478387779794312\n"
     ]
    }
   ],
   "source": [
    "print('AUC on test data:', lr_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a338a1-984d-4d91-bb67-84714730e47d",
   "metadata": {},
   "source": [
    "## Random Forest Modeling Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4090478-2a20-49d6-9a0a-3a739c8277a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbc_model_gscv(X_train, y_train, smote = True):\n",
    "    # One-Hot Enconde categorical features\n",
    "    cat_feats = X_train.columns[X_train.dtypes == 'object']\n",
    "    \n",
    "    # An imblearn pipeline is needed when using SMOTE in the pipeline because the function doesn't \n",
    "    # have a fit_transform method and can't be used with a sklearn pipeline. Also, the imblearn \n",
    "    # pipeline will ensure that SMOTE is only applied to training data, even in cross-validation.\n",
    "    if smote == True: \n",
    "        pipeline = imbpipeline(steps = [('ohe', ColumnTransformer(transformers = [('ohe', OneHotEncoder(handle_unknown = 'ignore', sparse = False), cat_feats)], remainder = 'passthrough')),\n",
    "                                        # Inputing missing continuous feature data with chained equations\n",
    "                                        ('mice', IterativeImputer(max_iter = 20, tol = 0.01, n_nearest_features = 50, random_state = 42, verbose = 1)), \n",
    "                                        # Creating synthetic data from the minority class\n",
    "                                        ('smote', SMOTE(k_neighbors = 10, random_state = 42)), \n",
    "                                        # Attempting to normalize the features with the yeo-johnson transformation (box-cox also an option, but requires all data to be positive)\n",
    "                                        ('gaussian', PowerTransformer()),\n",
    "                                        # Robust scaling of the data, rather than Standard scaling, because it is less impacted by outliers\n",
    "                                        ('scaler', RobustScaler()),\n",
    "                                        ('classifier', CatBoostClassifier(task_type = 'GPU', devices = '0:1', verbose = 0))\n",
    "                                       ])\n",
    "    # When not using SMOTE, a sklearn pipeline works fine\n",
    "    else:\n",
    "        pipeline = Pipeline(steps = [('ohe', ColumnTransformer(transformers = [('ohe', OneHotEncoder(handle_unknown = 'ignore', sparse = False), cat_feats)], remainder = 'passthrough')),\n",
    "                                     # Inputing missing continuous feature data with chained equations\n",
    "                                     ('mice', IterativeImputer(max_iter = 20, tol = 0.01, n_nearest_features = 50, random_state = 42, verbose = 1)),\n",
    "                                     # Attempting to normalize the features with the yeo-johnson transformation (box-cox also an option, but requires all data to be positive)\n",
    "                                     ('gaussian', PowerTransformer()),\n",
    "                                      # Robust scaling of the data, rather than Standard scaling, because it is less impacted by outliers\n",
    "                                     ('scaler', RobustScaler()),\n",
    "                                     ('classifier', CatBoostClassifier(task_type = 'GPU', devices = '0:1', verbose = 0))\n",
    "                                    ])\n",
    "    # Specify how the folds should be created in GridSearchCV\n",
    "    stratified_kfold = StratifiedKFold(n_splits=5,\n",
    "                                       shuffle=True,\n",
    "                                       random_state=42)\n",
    "    # Define the parameter grid for GridSearchCV\n",
    "    param_grid = {'classifier__iterations': [1000]} # 'classifier__iterations': [1000], 'classifier__n_estimators': [100, 200, 300], 'classifier__max_depth': [10, 15, 20]\n",
    "    grid_search = GridSearchCV(estimator = pipeline,\n",
    "                               param_grid = param_grid,\n",
    "                               scoring = 'roc_auc',\n",
    "                               cv = stratified_kfold,\n",
    "                               n_jobs = 1,\n",
    "                               verbose = 1)\n",
    "    \n",
    "    \n",
    "    grid_search.fit(X_train, y_train)\n",
    "    return(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c09cc-ed1c-4b21-abd0-213c6db8b81e",
   "metadata": {},
   "source": [
    "### Random Forest Classifier without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d371ac29-7c14-4bd7-988d-9c425446dd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 4772.316650594342, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 955.7651025295002, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akipp\\anaconda3\\envs\\py38env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 4522.071574019754, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 1121.1487511084902, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 772.098752699685, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akipp\\anaconda3\\envs\\py38env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 4726.374474804047, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 1289.3303725232347, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 910.748209593336, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akipp\\anaconda3\\envs\\py38env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 5156.155298589655, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 1118.8323782043637, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 559.6982391417464, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akipp\\anaconda3\\envs\\py38env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 4853.875315268089, scaled tolerance: 1052.68939228 \n",
      "[IterativeImputer] Change: 1400.5024189753487, scaled tolerance: 1052.68939228 \n",
      "[IterativeImputer] Change: 537.7464642603584, scaled tolerance: 1052.68939228 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\akipp\\anaconda3\\envs\\py38env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:3253: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (36000, 185)\n",
      "[IterativeImputer] Change: 4762.814312581376, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 902.9395589654421, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    }
   ],
   "source": [
    "cbc_model = cbc_model_gscv(X_train, y_train, smote = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffd2cbe3-cbeb-4902-b5ae-1a23b4cf6807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters determine during grid search: {'classifier__iterations': 1000}\n",
      "Best AUC score on cross-validation data: 0.803347346220171\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters determine during grid search:', cbc_model.best_params_)\n",
    "print('Best AUC score on cross-validation data:', cbc_model.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35b5137f-2bd4-440e-a94a-dc09964a63f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__iterations</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69.108671</td>\n",
       "      <td>6.487655</td>\n",
       "      <td>0.226608</td>\n",
       "      <td>0.046409</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__iterations': 1000}</td>\n",
       "      <td>0.798605</td>\n",
       "      <td>0.802302</td>\n",
       "      <td>0.804163</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.805834</td>\n",
       "      <td>0.803347</td>\n",
       "      <td>0.002706</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      69.108671      6.487655         0.226608        0.046409   \n",
       "\n",
       "  param_classifier__iterations                            params  \\\n",
       "0                         1000  {'classifier__iterations': 1000}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.798605           0.802302           0.804163           0.805833   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.805834         0.803347        0.002706                1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cbc_model.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2926ea5-b597-4c9b-84b5-bb673055f256",
   "metadata": {},
   "source": [
    "### Cat Boost Classifier with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cd732bb-82a8-4f4f-b7f1-f94760d99374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 4772.316650594342, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 955.7651025295002, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 4522.071574019754, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 1121.1487511084902, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 772.098752699685, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 4726.374474804047, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 1289.3303725232347, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 910.748209593336, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 5156.155298589655, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 1118.8323782043637, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 559.6982391417464, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (28800, 185)\n",
      "[IterativeImputer] Change: 4853.875315268089, scaled tolerance: 1052.68939228 \n",
      "[IterativeImputer] Change: 1400.5024189753487, scaled tolerance: 1052.68939228 \n",
      "[IterativeImputer] Change: 537.7464642603584, scaled tolerance: 1052.68939228 \n",
      "[IterativeImputer] Early stopping criterion reached.\n",
      "[IterativeImputer] Completing matrix with shape (7200, 185)\n",
      "[IterativeImputer] Completing matrix with shape (36000, 185)\n",
      "[IterativeImputer] Change: 4762.814312581376, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Change: 902.9395589654421, scaled tolerance: 1054.43357829 \n",
      "[IterativeImputer] Early stopping criterion reached.\n"
     ]
    }
   ],
   "source": [
    "cbc_model_smote = cbc_model_gscv(X_train, y_train, smote = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a534d83f-e1f7-47cf-a9bc-19a03c8404a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model parameters determine during grid search: {'classifier__iterations': 1000}\n",
      "Best AUC score on cross-validation data: 0.8044069664557026\n"
     ]
    }
   ],
   "source": [
    "print('Best model parameters determine during grid search:', cbc_model_smote.best_params_)\n",
    "print('Best AUC score on cross-validation data:', cbc_model_smote.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b868c4f-13df-428b-9b4e-13a56f0f0124",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_classifier__iterations</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76.841433</td>\n",
       "      <td>2.491626</td>\n",
       "      <td>0.209445</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>1000</td>\n",
       "      <td>{'classifier__iterations': 1000}</td>\n",
       "      <td>0.799835</td>\n",
       "      <td>0.802491</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.804667</td>\n",
       "      <td>0.809636</td>\n",
       "      <td>0.804407</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0      76.841433      2.491626         0.209445        0.014029   \n",
       "\n",
       "  param_classifier__iterations                            params  \\\n",
       "0                         1000  {'classifier__iterations': 1000}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.799835           0.802491           0.805405           0.804667   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.809636         0.804407        0.003255                1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(cbc_model_smote.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5410254-83f0-4475-ad47-2224e1afa701",
   "metadata": {},
   "source": [
    "From the above results, it appears that while the classes are imbalanced, using SMOTE to aftifically balance the classes does not provide much, if any, benefit so it can be dropped from use in Cat Boost Classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04ae238-6b71-4e65-9204-577887eab541",
   "metadata": {},
   "source": [
    "### Cat Boost Classifier Intermediate Test Data Score - Without SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c633b42-3b61-43d4-8912-6c5580538e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (4000, 185)\n",
      "AUC on test data: 0.7943153861665659\n"
     ]
    }
   ],
   "source": [
    "print('AUC on test data:', cbc_model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3852475-6c65-43b4-9e34-e142783b4dd3",
   "metadata": {},
   "source": [
    "## Final Test Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe99076d-082e-4323-b0e7-0885ac59cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_name = 'exercise_40_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fd5035c-e0bc-41f1-bd10-08ab4b9624b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_path + test_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9676373b-b88c-4f16-9339-9cf82d59cf0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_cleaning(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "06c9ffab-673b-40d3-ac25-ecdab55896fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (10000, 185)\n",
      "[IterativeImputer] Completing matrix with shape (10000, 185)\n"
     ]
    }
   ],
   "source": [
    "lr_test_probs = pd.DataFrame(lr_model.predict_proba(X_test))\n",
    "lr_test_probs.columns = ['prob_class_0', 'prob_class_1']\n",
    "lr_test_probs.drop(columns = ['prob_class_0'], inplace = True)\n",
    "cbc_test_probs = pd.DataFrame(cbc_model.predict_proba(X_test))\n",
    "cbc_test_probs.columns = ['prob_class_0', 'prob_class_1']\n",
    "cbc_test_probs.drop(columns = ['prob_class_0'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e9194267-d6f4-4c68-a080-112fbe19efab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_test_probs.to_csv(data_path + 'glmresults.csv', header = False, index = False)\n",
    "cbc_test_probs.to_csv(data_path + 'nonglmresults.csv', header = False, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py38env",
   "language": "python",
   "name": "py38env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
